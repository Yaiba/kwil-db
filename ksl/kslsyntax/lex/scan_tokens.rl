
package lex

import (
    "bytes"

    "github.com/kwilteam/ksl"
)

// Code generated by scan_tokens.rl; DO NOT EDIT.
%%{
  # (except when you are actually in scan_tokens.rl here, so edit away!)

  machine ksltok;
  write data;
}%%

func ScanTokens(data []byte, filename string, start ksl.Pos) []Token {
    stripData := stripUTF8BOM(data)
    start.Offset += len(data) - len(stripData)
    data = stripData

    f := &tokenAccum{
        Filename:  filename,
        Bytes:     data,
        Pos:       start,
        StartByte: start.Offset,
    }

    %%{
        include UnicodeDerived "unicode_derived.rl";

        UTF8Cont = 0x80 .. 0xBF;
        AnyUTF8 = (
            0x00..0x7F |
            0xC0..0xDF . UTF8Cont |
            0xE0..0xEF . UTF8Cont . UTF8Cont |
            0xF0..0xF7 . UTF8Cont . UTF8Cont . UTF8Cont
        );
        BrokenUTF8 = any - AnyUTF8;
        IntegerLit = ('+'|'-')?[0-9]+;
        FloatLit = ('+'|'-')?[0-9]*'.'[0-9]+;
        NumberLitContinue = (digit|'.'|('e'|'E') ('+'|'-')? digit);
        NumberLit = digit ("" | (NumberLitContinue - '.') | (NumberLitContinue* (NumberLitContinue - '.')));
        Ident = [a-zA-Z] [a-zA-Z0-9_]*;
        QualifiedIdent = Ident ('.' Ident)+;
        SelfToken = "[" | "]" | "(" | ")" | "." | "," | "@" | "$" | "+" | "-" | "=" | "!" | "?" | ":" | "\n" | ";" | "`" | "'";
        Newline = '\r' ? '\n';
        EndOfLine = Newline;
        NullLit = "null";
        BoolLit = "true" | "false";
        BeginString = '"';
        BeginHeredoc = '<<' ('-')? Ident Newline;

        Comment = (
            ("#" (any - EndOfLine)* :>> EndOfLine?) |
            ("//" (any - EndOfLine)* :>> EndOfLine?)
        );

        DocComment = "///" (any - EndOfLine)* :>> EndOfLine?;
        Spaces = (' ' | 0x09)+;

        action beginHeredocTemplate {
            token(TokenHeredocBegin);
            marker := data[ts+2:te-1]
            if marker[0] == '-' {
                marker = marker[1:]
            }
            if marker[len(marker)-1] == '\r' {
                marker = marker[:len(marker)-1]
            }

            heredocs = append(heredocs, heredocInProgress{
                Marker:      marker,
                StartOfLine: true,
            })

            fcall heredocTemplate;
        }

        action heredocLiteralEOL {
            topdoc := &heredocs[len(heredocs)-1]
            if topdoc.StartOfLine {
                maybeMarker := bytes.TrimSpace(data[ts:te])
                if bytes.Equal(maybeMarker, topdoc.Marker) {
                    nls := te-1
                    nle := te
                    te--
                    if data[te-1] == '\r' {
                        // back up one more byte
                        nls--
                        te--
                    }
                    token(TokenHeredocEnd);
                    ts = nls
                    te = nle
                    token(TokenNewline);
                    heredocs = heredocs[:len(heredocs)-1]
                    fret;
                }
            }

            topdoc.StartOfLine = true;
            token(TokenStringLit);
        }

        action heredocLiteralMidline {
            heredocs[len(heredocs)-1].StartOfLine = false;
            token(TokenStringLit);
        }

        action quotedStringLiteral {
            ts--
            te++
            token(TokenQuotedLit);
        }

        EndString = '"';
        NewlineChars = ("\r"|"\n");
        NewlineCharsSeq = NewlineChars+;
        StringLiteralChars = (AnyUTF8 - NewlineChars);
        QuotedStringLiteralWithEsc = ('\\' StringLiteralChars) | (StringLiteralChars - ('"' | "\\"));
        QuotedStringLiteral = QuotedStringLiteralWithEsc+;
        HeredocStringLiteral = StringLiteralChars*;

        stringTemplate := |*
            EndString             => { fret; };
            QuotedStringLiteral   => quotedStringLiteral;
            NewlineCharsSeq       => { token(TokenQuotedNewline); };
            AnyUTF8               => { token(TokenInvalid); };
            BrokenUTF8            => { token(TokenBadUTF8); };
        *|;

        heredocTemplate := |*
            HeredocStringLiteral EndOfLine => heredocLiteralEOL;
            HeredocStringLiteral  => heredocLiteralMidline;
            BrokenUTF8            => { token(TokenBadUTF8); };
        *|;

        main := |*
            Spaces           => {};
            IntegerLit       => { token(TokenIntegerLit); };
            FloatLit         => { token(TokenFloatLit); };
            NumberLit        => { token(TokenNumberLit) };
            BoolLit          => { token(TokenBoolLit) };
            NullLit          => { token(TokenNullLit) };
            QualifiedIdent   => { token(TokenQualifiedIdent) };
            Ident            => { token(TokenIdent) };
            DocComment       => { token(TokenDocComment) };
            Comment          => { token(TokenComment) };
            Newline          => { token(TokenNewline) };
            SelfToken        => { selfToken() };

            "{"              => { token(TokenLBrace) };
            "}"              => { token(TokenRBrace) };

            BeginString      => { fcall stringTemplate; };
            BeginHeredoc     => beginHeredocTemplate;

            BrokenUTF8       => { token(TokenBadUTF8) };
            AnyUTF8          => { token(TokenInvalid) };
        *|;

    }%%

    // Ragel state
	p := 0  // "Pointer" into data
	pe := len(data) // End-of-data "pointer"
    ts := 0
    te := 0
    act := 0
    eof := pe
    var stack []int
    var top int

    cs := ksltok_en_main

    var heredocs []heredocInProgress // stack of heredocs we're currently processing

    %%{
        prepush {
            stack = append(stack, 0);
        }
        postpop {
            stack = stack[:len(stack)-1];
        }
    }%%

    // Make Go compiler happy
    _ = ts
    _ = te
    _ = act
    _ = eof

    token := func (ty TokenType) {
        f.emitToken(ty, ts, te)
    }
    selfToken := func () {
        b := data[ts:te]
        if len(b) != 1 {
            // should never happen
            panic("selfToken only works for single-character tokens")
        }
        f.emitToken(TokenType(b[0]), ts, te)
    }

    %%{
        write init nocs;
        write exec;
    }%%

    // If we fall out here without being in a final state then we've
    // encountered something that the scanner can't match, which we'll
    // deal with as an invalid.
    if cs < ksltok_first_final {
        f.emitToken(TokenInvalid, ts, len(data))
    }

    // We always emit a synthetic EOF token at the end, since it gives the
    // parser position information for an "unexpected EOF" diagnostic.
    f.emitToken(TokenEOF, len(data), len(data))

    return f.Tokens
}
